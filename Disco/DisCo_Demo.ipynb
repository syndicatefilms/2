{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syndicatefilms/2/blob/main/Disco/DisCo_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Qu-pX4GDlgs",
        "outputId": "8d7b6ce8-7a5b-4609-8d6a-18440266d5ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 30 07:42:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Clone the github repo"
      ],
      "metadata": {
        "id": "N7Som16t69XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Wangt-CN/DisCo"
      ],
      "metadata": {
        "id": "kKByNFtrfV7M",
        "outputId": "997b7a51-b7a7-4a66-ab1d-d6978cdc7fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DisCo'...\n",
            "remote: Enumerating objects: 870, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 870 (delta 72), reused 63 (delta 55), pack-reused 743 (from 1)\u001b[K\n",
            "Receiving objects: 100% (870/870), 98.36 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (196/196), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Install the package\n",
        "\n",
        "Ps: Most errors are due to the unsuccessful package installation, please check the installation carefully.\n"
      ],
      "metadata": {
        "id": "mpXDRYzO6rEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install --user progressbar psutil pymongo simplejson yacs boto3 pyyaml ete3 easydict deprecated future django orderedset python-magic datasets h5py omegaconf einops ipdb\n",
        "!pip install --user --exists-action w -r DisCo/requirements.txt\n",
        "!pip install git+https://github.com/microsoft/azfuse.git\n",
        "\n",
        "## for acceleration\n",
        "!pip install --user deepspeed==0.6.3"
      ],
      "metadata": {
        "id": "37UDwQVxfp4T",
        "outputId": "b1adbb37-dea7-46c0-9924-961792488130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp311-cp311-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m544.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1+cu117 (from versions: 0.1.6, 0.2.0, 0.15.0+cu117, 0.15.1, 0.15.1+cu117, 0.15.2, 0.15.2+cu117, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1+cu117\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.19.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.36.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Collecting ete3\n",
            "  Downloading ete3-3.1.3.tar.gz (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (1.13)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (1.2.18)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Collecting django\n",
            "  Downloading Django-5.1.5-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting orderedset\n",
            "  Downloading orderedset-2.0.3.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.12.1)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting botocore<1.37.0,>=1.36.9 (from boto3)\n",
            "  Downloading botocore-1.36.9-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated) (1.17.2)\n",
            "Collecting asgiref<4,>=3.8.1 (from django)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from django) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.11/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.9->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.37.0,>=1.36.9->boto3) (2.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.9->boto3) (1.17.0)\n",
            "Downloading pymongo-4.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplejson-3.19.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading boto3-1.36.9-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Django-5.1.5-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading botocore-1.36.9-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: progressbar, ete3, orderedset, antlr4-python3-runtime\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12066 sha256=db410d9d12a31f690f51b7918bfd7f89de5c3ba29aa826483165ec548fb32bdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/bb/b2/5353b966ac6f3c5e1000629a9a5f6aed41794487f551e32efc\n",
            "  Building wheel for ete3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ete3: filename=ete3-3.1.3-py3-none-any.whl size=2273787 sha256=17863a59c89147aa17ba153ac24c0838de717d93543c8f4e9f5a5086b025c686\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/a8/60/0a29caa9f8ceb7316704be63c1578ab13c36668abb646366ac\n",
            "  Building wheel for orderedset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orderedset: filename=orderedset-2.0.3-cp311-cp311-linux_x86_64.whl size=390430 sha256=90cad8095faa2fe10c6953e9e703ff758c746e2500b04f583060b191e5bbfd2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/fa/73/52d0af400e2afb38c29e57a6de7d62c86f48c15adf5fd70975\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=dcab1c76afd55bb29416b5cbed0a367ac4ac982a858cf1de412cd629386ea47a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built progressbar ete3 orderedset antlr4-python3-runtime\n",
            "Installing collected packages: progressbar, orderedset, ete3, antlr4-python3-runtime, yacs, xxhash, simplejson, python-magic, omegaconf, jmespath, jedi, fsspec, dnspython, dill, asgiref, pymongo, multiprocess, django, botocore, s3transfer, ipdb, datasets, boto3\n",
            "\u001b[33m  WARNING: The script ete3 is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script django-admin is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script ipdb3 is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 asgiref-3.8.1 boto3-1.36.9 botocore-1.36.9 datasets-3.2.0 dill-0.3.8 django-5.1.5 dnspython-2.7.0 ete3-3.1.3 fsspec-2024.9.0 ipdb-0.13.13 jedi-0.19.2 jmespath-1.0.1 multiprocess-0.70.16 omegaconf-2.3.0 orderedset-2.0.3 progressbar-2.5 pymongo-4.11 python-magic-0.4.27 s3transfer-0.11.2 simplejson-3.19.3 xxhash-3.5.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "ae49b8f430844e25a36f1124daeaa1d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r DisCo/requirements.txt (line 1)) (0.19.4)\n",
            "Collecting ffmpeg-python (from -r DisCo/requirements.txt (line 2))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r DisCo/requirements.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r DisCo/requirements.txt (line 4)) (1.0.14)\n",
            "Collecting ftfy==6.0.3 (from -r DisCo/requirements.txt (line 5))\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardX==2.4.1 (from -r DisCo/requirements.txt (line 6))\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: datasets in /root/.local/lib/python3.11/site-packages (from -r DisCo/requirements.txt (line 9)) (3.2.0)\n",
            "Collecting rouge_score (from -r DisCo/requirements.txt (line 10))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: omegaconf in /root/.local/lib/python3.11/site-packages (from -r DisCo/requirements.txt (line 11)) (2.3.0)\n",
            "Collecting diffusers==0.14.0 (from diffusers[torch]==0.14.0->-r DisCo/requirements.txt (line 12))\n",
            "  Downloading diffusers-0.14.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting decord==0.6.0 (from -r DisCo/requirements.txt (line 13))\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting git+https://github.com/microsoft/azfuse.git\n",
            "  Cloning https://github.com/microsoft/azfuse.git to /tmp/pip-req-build-ddrrx03z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/azfuse.git /tmp/pip-req-build-ddrrx03z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U xformers"
      ],
      "metadata": {
        "id": "ZMfiYfxAyLmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Download the pretrained model\n",
        "Feel free to use our other [checkpoints](https://github.com/Wangt-CN/DisCo#model-checkpoint-google-cloud-tiktok-training-data-fid-fvd-188--more-tiktok-style-training-data-fid-fvd-157) or change to your own model"
      ],
      "metadata": {
        "id": "YkfPye5C7FDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/lambdalabs/sd-image-variations-diffusers\n",
        "!wget https://storage.googleapis.com/disco-checkpoint-share/checkpoint_ft/moretiktok_nocfg/mp_rank_00_model_states.pt"
      ],
      "metadata": {
        "id": "v5FjMXqkh827"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Start Running"
      ],
      "metadata": {
        "id": "5-u3ohQt7o2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/DisCo')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "n2knZKbPsxsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall colorlog -y\n",
        "!pip uninstall deepdish -y\n",
        "!pip uninstall configobj -y\n",
        "!pip uninstall json_lines -y\n",
        "!pip install colorlog deepdish configobj json_lines"
      ],
      "metadata": {
        "id": "tK1pUheJbWr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall einops -y"
      ],
      "metadata": {
        "id": "T-uP6jcJcJR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "1EYe-cm8cgoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "v4U3pLmYcyJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall huggingface_hub -y"
      ],
      "metadata": {
        "id": "2SJt4AqJdHNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "AH-y9q7jdO0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "hGNAwm3pdYsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall deepspeed -y"
      ],
      "metadata": {
        "id": "YQyLaOy5drzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeed"
      ],
      "metadata": {
        "id": "zfA9AdNPdyym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall hjson -y\n",
        "!pip install hjson"
      ],
      "metadata": {
        "id": "eNYAx9_neRLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "gcDVdMoNei1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall deprecated -y\n",
        "!pip install deprecated"
      ],
      "metadata": {
        "id": "gJwkx7EqezqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"WANDB_ENABLE\"] = \"0\"\n",
        "\n",
        "from utils.wutils_ldm import *\n",
        "from agent import Agent_LDM, WarmupLinearLR, WarmupLinearConstantLR\n",
        "import torch\n",
        "from config import BasicArgs\n",
        "from utils.lib import *\n",
        "# from utils.args import parse_with_cf\n",
        "from utils.dist import dist_init\n",
        "from dataset.tsv_dataset import make_data_sampler, make_batch_data_sampler\n",
        "from finetune_sdm_yaml import get_loader_info, make_data_loader\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')"
      ],
      "metadata": {
        "id": "513HsIP_sHMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall diffusers -y"
      ],
      "metadata": {
        "id": "Nbv67O8Rft8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers==0.14.0"
      ],
      "metadata": {
        "id": "quRzdae_ikYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.args import sharedArgs\n",
        "manual_args = ['--cf', 'config/ref_attn_clip_combine_controlnet/app_demo_image_edit.py', '--eval_visu', 'True', '--root_dir', '/content/run_test', '--local_train_batch_size', '32', '--local_eval_batch_size', '32', '--log_dir', 'exp/tiktok_ft', '--epochs', '20', '--deepspeed', '--eval_step', '500',\n",
        "               '--save_step', '500', '--gradient_accumulate_steps', '1', '--learning_rate', '2e-4', '--fix_dist_seed', 'True', '--loss_target',\n",
        "               'noise', '--unet_unfreeze_type', 'all', '--guidance_scale', '3', '--refer_sdvae', 'True', '--ref_null_caption', 'False', '--combine_clip_local', 'True', '--combine_use_mask', 'True', '--conds', 'poses','masks', '--pretrained_model', '/content/mp_rank_00_model_states.pt', '--pretrained_model_path', '/content/sd-image-variations-diffusers', '--eval_save_filename', 'try']\n",
        "parsed_args = sharedArgs.parser.parse_args(args=manual_args)\n",
        "\n",
        "###### process the args #######\n",
        "if parsed_args.root_dir:\n",
        "    BasicArgs.root_dir = parsed_args.root_dir\n",
        "else:\n",
        "    parsed_args.root_dir = BasicArgs.root_dir\n",
        "parsed_args.pretrained_model_path = os.path.join(parsed_args.root_dir, parsed_args.pretrained_model_path)\n",
        "\n",
        "def parse_with_cf(parsed_args):\n",
        "    \"\"\"This function will set args based on the input config file.\n",
        "    (1) it only overwrites unset parameters,\n",
        "        i.e., these parameters not set from user command line input\n",
        "    (2) it also sets configs in the config file but declared in the parser\n",
        "    \"\"\"\n",
        "    # convert to EasyDict object,\n",
        "    # enabling access from attributes even for nested config\n",
        "    # e.g., args.train_datasets[0].name\n",
        "    args = edict(vars(parsed_args))\n",
        "    if os.path.exists(parsed_args.cf):\n",
        "        cf = import_filename(parsed_args.cf)\n",
        "        config_args = edict(vars(cf.Args))\n",
        "        override_keys = {arg[2:].split(\"=\")[0] for arg in manual_args\n",
        "                         if arg.startswith(\"--\")}\n",
        "        # import pdb;pdb.set_trace()\n",
        "        for k, v in config_args.items():\n",
        "            if k not in override_keys:\n",
        "                setattr(args, k, v)\n",
        "    else:\n",
        "        raise NotImplementedError('Config filename %s does not exist.' % args.cf)\n",
        "    return args\n",
        "\n",
        "args = parse_with_cf(parsed_args)\n",
        "\n",
        "args.n_gpu = T.cuda.device_count() # local size\n",
        "args.local_size = args.n_gpu\n",
        "if args.root_dir not in args.log_dir:\n",
        "    args.log_dir = os.path.join(args.root_dir, args.log_dir)\n",
        "if args.stepwise_sample_depth == -1:\n",
        "    args.interpolation = None\n",
        "    args.interpolate_mode = None\n",
        "if args.interpolation != \"interpolate\":\n",
        "    args.interpolate_mode = None\n",
        "\n",
        "assert args.eval_step > 0, \"eval_step must be positive\"\n",
        "assert args.save_step > 0, \"save_step must be positive\"\n",
        "\n",
        "dist_init(args)\n",
        "args.dist = args.distributed\n",
        "args.nodes = args.num_nodes\n",
        "args.world_size = args.num_gpus\n",
        "args.train_batch_size = args.local_train_batch_size * args.world_size\n",
        "args.eval_batch_size = args.local_eval_batch_size * args.world_size\n",
        "#############################################\n",
        "\n",
        "cf = import_filename(args.cf)\n",
        "Net, inner_collect_fn = cf.Net, cf.inner_collect_fn\n",
        "\n",
        "dataset_cf = import_filename(args.dataset_cf)\n",
        "BaseDataset = dataset_cf.BaseDataset\n",
        "\n",
        "# args = update_args(parsed_args, args)\n",
        "\n",
        "# init models\n",
        "logger.info('Building models...')\n",
        "model = Net(args)\n",
        "print(f\"Args: {edict(vars(args))}\")"
      ],
      "metadata": {
        "id": "pCuG7qZ3zjYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.warning(\"Do eval_visu...\")\n",
        "if getattr(args, 'refer_clip_preprocess', None):\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val', preprocesser=model.feature_extractor)\n",
        "else:\n",
        "    eval_dataset = BaseDataset(args, args.val_yaml, split='val')\n",
        "eval_dataloader, eval_info = make_data_loader(\n",
        "    args, args.local_eval_batch_size,\n",
        "    eval_dataset)\n",
        "\n",
        "\n",
        "trainer = Agent_LDM(args=args, model=model)\n",
        "trainer.eval_demo_pre()"
      ],
      "metadata": {
        "id": "OmhxcD304rY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image):\n",
        "    if not image.mode == \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference(reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    fg_mask = load_image(fg_mask)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    bg_mask = load_image(bg_mask)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, fg_mask, ref_bg_image, bg_mask, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image\n",
        "\n",
        "@torch.no_grad()\n",
        "def inference_masked(reference_fg, ref_bg_image, skeleton_img, *args, **kwargs):\n",
        "    reference_fg = load_image(reference_fg)\n",
        "    ref_bg_image = load_image(ref_bg_image)\n",
        "    skeleton_img = load_image(skeleton_img)\n",
        "\n",
        "    input_data = [reference_fg, ref_bg_image, skeleton_img]\n",
        "    output_image = trainer.eval_demo_run_masked(input_data, eval_dataset=eval_dataset)\n",
        "    return output_image"
      ],
      "metadata": {
        "id": "fF-xqrj95ekN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Launch the gradio demo"
      ],
      "metadata": {
        "id": "wv2ZhLq_77Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "oe4-FQCfmYqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "'''\n",
        "launch app\n",
        "'''\n",
        "title = \"DisCo Demo (Video Demo Comming Soon!)\"\n",
        "description = \"\"\"<p style='text-align: center'> <a href='https://disco-dance.github.io/' target='_blank'>Project Page</a> | <a href='https://arxiv.org/pdf/2212.11270.pdf' target='_blank'>Paper</a> | <a href='https://github.com/microsoft/X-Decoder' target='_blank'>Github Repo</a> | <a href='https://youtu.be/wYp6vmyolqE' target='_blank'>Video</a> </p>\n",
        "<p>Skip the queue by duplicating this space and upgrading to GPU in settings</p>\n",
        "<a href=\"https://huggingface.co/spaces/xdecoder/Demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    # DisCo Demo (Video Demo Comming Soon!)\n",
        "    Start edit the human with provided human foreground, background, pose.\n",
        "\n",
        "    Note that for self-uploaded images, TikTok-Style human images are preferred.\n",
        "\n",
        "    [Project Page](https://disco-dance.github.io/) | [Github](https://github.com/Wangt-CN/DisCo)\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row().style(equal_height=False):\n",
        "        with gr.Column(min_width=400, scale=2):\n",
        "            input_fg = gr.Image(type='pil',label=\"Foreground Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/fg/masked_images/00035.png\", \"./demo_data/fg/masked_images/00335.png\", \"./demo_data/fg/masked_images/00147.png\", \"./demo_data/fg/masked_images/00072.png\", \"./demo_data/fg/masked_images/00115.png\"], inputs=input_fg)\n",
        "\n",
        "            input_bg = gr.Image(type='pil',label=\"Background Image\")\n",
        "            gr.Examples(examples=[\"./demo_data/bg/masked_images/00035.png\", \"./demo_data/bg/masked_images/00335.png\", \"./demo_data/bg/masked_images/00147.png\", \"./demo_data/bg/masked_images/00072.png\", \"./demo_data/bg/masked_images/00115.png\"], inputs=input_bg)\n",
        "\n",
        "            input_pose = gr.Image(type='pil',label=\"Target Pose\",scale=1)\n",
        "            gr.Examples(examples=[\"./demo_data/pose_img/0049.png\",\"./demo_data/pose_img/0198.png\",\"./demo_data/pose_img/0213.png\",\"./demo_data/pose_img/0264.png\",\"./demo_data/pose_img/0144.png\",\"./demo_data/pose_img/0054.png\"], inputs=input_pose)\n",
        "\n",
        "            btn = gr.Button(\"Generate\")\n",
        "\n",
        "\n",
        "        with gr.Column(min_width=150):\n",
        "            output_img = gr.Image(type='pil',label=\"Edited Human Image\")\n",
        "\n",
        "    btn.click(inference_masked, inputs=[input_fg, input_bg, input_pose], outputs=[output_img])\n",
        "\n",
        "demo.queue(concurrency_count=2)\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "yvs61CCg5iZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}